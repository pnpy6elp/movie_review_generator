{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a748667",
   "metadata": {},
   "source": [
    "# Calculate Sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b58ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4af0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ec2a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings_test.txt', <http.client.HTTPMessage at 0x7efb82777310>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524ea305",
   "metadata": {},
   "outputs": [],
   "source": [
    "min1 = True\n",
    "min3 = \" \"\n",
    "\n",
    "\n",
    "train_data = pd.read_table('ratings_train.txt')\n",
    "test_data = pd.read_table('ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d8523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "test_data.drop_duplicates(subset=['document'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c785539d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28410/2535633430.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
      "/tmp/ipykernel_28410/2535633430.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace('^ +', \"\")\n",
      "/tmp/ipykernel_28410/2535633430.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
      "/tmp/ipykernel_28410/2535633430.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data['document'] = train_data['document'].str.replace('^ +', \"\")\n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "train_data = train_data.dropna(how = 'any')\n",
    "test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
    "test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n",
    "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50eeeb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145393/145393 [16:22<00:00, 147.97it/s]\n",
      "100%|██████████| 48852/48852 [06:18<00:00, 129.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenizing\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "okt = Okt()\n",
    "X_train = []\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(stopwords_removed_sentence)\n",
    "X_test = []\n",
    "for sentence in tqdm(test_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(stopwords_removed_sentence)\n",
    "tokenizer = Tokenizer(10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "y_train = np.array(train_data['label'])\n",
    "y_test = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5c8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]  # remove empty sample\n",
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "\n",
    "max_len = 30\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f8efe25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 11:03:53.994034: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef9a8063550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-09 11:03:53.994072: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-12-09 11:03:54.809576: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/1813 [..............................] - ETA: 3:37 - loss: 0.6944 - acc: 0.5156   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 11:03:56.339125: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1813/1813 [==============================] - ETA: 0s - loss: 0.4096 - acc: 0.8114\n",
      "Epoch 1: val_acc improved from -inf to 0.82911, saving model to best_model.h5\n",
      "1813/1813 [==============================] - 90s 47ms/step - loss: 0.4096 - acc: 0.8114 - val_loss: 0.3838 - val_acc: 0.8291\n",
      "Epoch 2/15\n",
      "   3/1813 [..............................] - ETA: 1:00 - loss: 0.3568 - acc: 0.8490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lim/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1813/1813 [==============================] - ETA: 0s - loss: 0.3487 - acc: 0.8478\n",
      "Epoch 2: val_acc improved from 0.82911 to 0.84297, saving model to best_model.h5\n",
      "1813/1813 [==============================] - 70s 38ms/step - loss: 0.3487 - acc: 0.8478 - val_loss: 0.3559 - val_acc: 0.8430\n",
      "Epoch 3/15\n",
      "1813/1813 [==============================] - ETA: 0s - loss: 0.3243 - acc: 0.8604\n",
      "Epoch 3: val_acc improved from 0.84297 to 0.85156, saving model to best_model.h5\n",
      "1813/1813 [==============================] - 67s 37ms/step - loss: 0.3243 - acc: 0.8604 - val_loss: 0.3445 - val_acc: 0.8516\n",
      "Epoch 4/15\n",
      "1813/1813 [==============================] - ETA: 0s - loss: 0.3039 - acc: 0.8717\n",
      "Epoch 4: val_acc improved from 0.85156 to 0.85415, saving model to best_model.h5\n",
      "1813/1813 [==============================] - 67s 37ms/step - loss: 0.3039 - acc: 0.8717 - val_loss: 0.3351 - val_acc: 0.8541\n",
      "Epoch 5/15\n",
      "1813/1813 [==============================] - ETA: 0s - loss: 0.2878 - acc: 0.8805\n",
      "Epoch 5: val_acc improved from 0.85415 to 0.85566, saving model to best_model.h5\n",
      "1813/1813 [==============================] - 67s 37ms/step - loss: 0.2878 - acc: 0.8805 - val_loss: 0.3320 - val_acc: 0.8557\n",
      "Epoch 6/15\n",
      "1813/1813 [==============================] - ETA: 0s - loss: 0.2732 - acc: 0.8886\n",
      "Epoch 6: val_acc did not improve from 0.85566\n",
      "1813/1813 [==============================] - 67s 37ms/step - loss: 0.2732 - acc: 0.8886 - val_loss: 0.3369 - val_acc: 0.8555\n",
      "Epoch 7/15\n",
      "1813/1813 [==============================] - ETA: 0s - loss: 0.2593 - acc: 0.8959\n",
      "Epoch 7: val_acc did not improve from 0.85566\n",
      "1813/1813 [==============================] - 67s 37ms/step - loss: 0.2593 - acc: 0.8959 - val_loss: 0.3472 - val_acc: 0.8525\n",
      "Epoch 8/15\n",
      "1813/1813 [==============================] - ETA: 0s - loss: 0.2457 - acc: 0.9025\n",
      "Epoch 8: val_acc did not improve from 0.85566\n",
      "1813/1813 [==============================] - 67s 37ms/step - loss: 0.2457 - acc: 0.9025 - val_loss: 0.3493 - val_acc: 0.8507\n",
      "Epoch 9/15\n",
      "1813/1813 [==============================] - ETA: 0s - loss: 0.2328 - acc: 0.9088\n",
      "Epoch 9: val_acc did not improve from 0.85566\n",
      "1813/1813 [==============================] - 67s 37ms/step - loss: 0.2328 - acc: 0.9088 - val_loss: 0.3561 - val_acc: 0.8505\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "# sentiment analysis model -> using LSTM\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "with tf.device('/cpu:0'):\n",
    "    embedding_dim = 100\n",
    "    hidden_units = 128\n",
    "    vocab_size = 10000\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim))\n",
    "    model.add(LSTM(hidden_units))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c00b352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f165bcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 18s 11ms/step - loss: 0.3425 - acc: 0.8514\n",
      "\n",
      " 테스트 정확도: 0.8514\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6a09751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "    score = float(loaded_model.predict(pad_new,verbose=0)) # 예측\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94f66cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 리뷰들에 sentiment score 넣기\n",
    "import os\n",
    "directory = './raw_data/'\n",
    "folder_list = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63d9f70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [12:38<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(json_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num):\n\u001b[0;32m---> 13\u001b[0m     sc \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     json_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sc\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m, in \u001b[0;36msentiment_predict\u001b[0;34m(new_sentence)\u001b[0m\n\u001b[1;32m      5\u001b[0m encoded \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences([new_sentence]) \u001b[38;5;66;03m# 정수 인코딩\u001b[39;00m\n\u001b[1;32m      6\u001b[0m pad_new \u001b[38;5;241m=\u001b[39m pad_sequences(encoded, maxlen \u001b[38;5;241m=\u001b[39m max_len) \u001b[38;5;66;03m# 패딩\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# 예측\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/keras/src/engine/training.py:2521\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2512\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2513\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2514\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2515\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2518\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2519\u001b[0m         )\n\u001b[0;32m-> 2521\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2529\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2532\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1678\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1285\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1284\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1301\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:314\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# performance.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    317\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m      A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2278\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2275\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:272\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    270\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1189\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;66;03m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1169\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1173\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    699\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:176\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 176\u001b[0m   concrete_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:171\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m   args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    169\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:393\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m placeholder_context \u001b[38;5;241m=\u001b[39m trace_type\u001b[38;5;241m.\u001b[39mInternalPlaceholderContext(\n\u001b[1;32m    391\u001b[0m     func_graph, placeholder_mapping)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m--> 393\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_func_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder_arguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m      \u001b[49m\u001b[43mplaceholder_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m args \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    396\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m placeholder_bound_args\u001b[38;5;241m.\u001b[39mkwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_type.py:323\u001b[0m, in \u001b[0;36mFunctionType.placeholder_arguments\u001b[0;34m(self, placeholder_context)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not generate placeholder value for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartially defined function type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    322\u001b[0m   placeholder_context\u001b[38;5;241m.\u001b[39mupdate_naming_scope(parameter\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 323\u001b[0m   arguments[parameter\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43mparameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m      \u001b[49m\u001b[43mplaceholder_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mBoundArguments(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py:271\u001b[0m, in \u001b[0;36mTensorSpec.placeholder_value\u001b[0;34m(self, placeholder_context)\u001b[0m\n\u001b[1;32m    269\u001b[0m     placeholder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_placeholder(context_graph, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m   placeholder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph_placeholder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m   \u001b[38;5;66;03m# Record the requested/user-specified name in case it's different than\u001b[39;00m\n\u001b[1;32m    275\u001b[0m   \u001b[38;5;66;03m# the uniquified name, for validation when exporting signatures.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m   placeholder\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39m_set_attr(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    277\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_user_specified_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m       attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue(s\u001b[38;5;241m=\u001b[39mcompat\u001b[38;5;241m.\u001b[39mas_bytes(name)))\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/framework/tensor.py:309\u001b[0m, in \u001b[0;36mTensorSpec._graph_placeholder\u001b[0;34m(self, graph, name)\u001b[0m\n\u001b[1;32m    307\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype_value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m: shape}\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    310\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlaceholder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    313\u001b[0m   \u001b[38;5;66;03m# TODO(b/262413656) Sometimes parameter names are not valid op names, in\u001b[39;00m\n\u001b[1;32m    314\u001b[0m   \u001b[38;5;66;03m# which case an unnamed placeholder is created instead. Update this logic\u001b[39;00m\n\u001b[1;32m    315\u001b[0m   \u001b[38;5;66;03m# to sanitize the name instead of falling back on unnamed placeholders.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarning(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[1;32m    669\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3381\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3378\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3379\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3381\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3382\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3383\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3384\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3385\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3386\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3387\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3388\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3389\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3390\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3391\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[1;32m   3392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1889\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1886\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 1889\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Operation(c_op, GraphTensor)\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(g)\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/lim/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1721\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39m_c_graph\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mas\u001b[39;00m c_graph:\n\u001b[0;32m-> 1721\u001b[0m   op_desc \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_NewOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_def\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[1;32m   1725\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(node_def\u001b[38;5;241m.\u001b[39mdevice))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "with tf.device('/cpu:0'): # colab에서 할 때는 이거 없애셈\n",
    "    for folder in tqdm(folder_list):\n",
    "        file_list = os.listdir(directory+\"/\"+folder)\n",
    "        num = len(file_list)\n",
    "        for i in range(0, num):\n",
    "            file = directory+\"/\"+folder+\"/%d.json\" % i\n",
    "            try:\n",
    "                with open(file, encoding='UTF-8') as json_file:\n",
    "                    json_data = json.load(json_file)\n",
    "                    num = len(json_data[\"data\"])\n",
    "                    for i in range(0, num):\n",
    "                        sc = sentiment_predict(json_data[\"data\"][i][\"review\"])\n",
    "                        json_data[\"data\"][i][\"sentiment score\"] = sc\n",
    "\n",
    "                    with open(file, 'w', encoding='UTF-8') as f:\n",
    "                        json.dump(json_data, f, ensure_ascii=False, indent=3)\n",
    "            except Exception:\n",
    "                print(i, \".json\", \" error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746702f3",
   "metadata": {},
   "source": [
    "# Correlation score : spearman coefficient between rating and sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "414a54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pandas import json_normalize\n",
    "\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cname = [\"rating\", \"sentiment\", \"correlation\",\"review\",\"spearman\",\"sympathy\",\"unsympathy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bcb375",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dit = {'1987':'1987',\n",
    "\n",
    "'a taxi driver':'택시운전사',\n",
    "\n",
    "'assassination':'암살',\n",
    "\n",
    "'confidential assignment':'공조',\n",
    "\n",
    "'intimate stranger':'완벽한 타인',\n",
    "\n",
    "'the outlaws':'범죄도시'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd3619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for folder in tqdm(folder_list):\n",
    "    data_list = []\n",
    "    file_list = os.listdir(directory+\"/\"+folder)\n",
    "    num = len(file_list)\n",
    "    for i in range(0, num):\n",
    "        file = directory+\"/\"+folder+\"/%d.json\" % i\n",
    "        try:\n",
    "            with open(file, encoding='UTF-8') as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "                num = len(json_data[\"data\"])\n",
    "                if(num>=3): # 리뷰 수가 3개 이상인 유저들의 데이터만\n",
    "                    dt = []\n",
    "                    ct = 0\n",
    "                    t_1 = [] # rating, predict\n",
    "                    t_2 = [] # sentiment score, test\n",
    "                    t_3 = []\n",
    "                    for i in range(0, num):\n",
    "                        if(json_data[\"data\"][x][\"title\"]==movie_dit[str(folder)]):\n",
    "                            if(ct == 0):\n",
    "                                if(len(json_data[\"data\"][x][\"review\"])<=140):\n",
    "                                    dt.append(int(json_data[\"data\"][x][\"rating\"])) # 현재 영화에 대한 평점\n",
    "                                    dt.append(json_data[\"data\"][x][\"sentiment score\"]) # 현재 영화에 대한 감성점수\n",
    "                                    dt.append(abs(int(json_data[\"data\"][x][\"rating\"])/10 - json_data[\"data\"][x][\"sentiment score\"])) # 평점과 감성점수의 편차\n",
    "                                    dt.append(json_data[\"data\"][x][\"review\"]) # 현재 영화에 대한 리뷰텍스트\n",
    "                                    ct += 1\n",
    "                        t_1.append(int(json_data[\"data\"][x][\"rating\"]))\n",
    "                        t_2.append(json_data[\"data\"][x][\"sentiment score\"])\n",
    "                    spearman, _ = spearmanr(t_1, t_2)\n",
    "                    dt.append(spearman)\n",
    "                    dt.append(json_data[\"sympathy\"])\n",
    "                    dt.append(json_data[\"unsympathy\"])\n",
    "                    data_list.append(dt)\n",
    "\n",
    "        except Exception:\n",
    "            print(i, \".json\", \" error\")\n",
    "        df = pd.DataFrame(data_list, columns=cname)\n",
    "        fname = \"./preprocessed_data/\"+folder+\".csv\"\n",
    "        df = df.dropna(axis=0)\n",
    "        df.to_csv(fname,encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61580eb",
   "metadata": {},
   "source": [
    "# Labeling - 상위 30%는 1, 하위 30%는 0 -> 모델이 잘 학습될 수 있도록 train data에 이러한 제한을 둚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5542e2",
   "metadata": {},
   "source": [
    "# outlaws가 평론을 생성할 영화임. 나머지 영화들로 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1cee21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "file_list = [i for i in os.listdir(\"./preprocessed_data\") if i.endswith(\".csv\") ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2011ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1987.csv',\n",
       " 'the outlaws.csv',\n",
       " 'a taxi driver.csv',\n",
       " 'assassination.csv',\n",
       " 'intimate stranger.csv',\n",
       " 'confidential assignment.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad87526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    if file != 'the outlaws.csv':\n",
    "        df = pd.read_csv(\"./preprocessed_data/\"+file, sep=\",\")\n",
    "        df = df[[\"rating\", \"sentiment\", \"correlation\",\"review\",\"spearman\"]]\n",
    "        df[\"spearman\"] = df[\"spearman\"].abs() # 절대값으로 변환, 상관계수가 음의 방향으로 커도 상관관계의 정도가 큰 것이기 때문\n",
    "        df = df.sort_values(by=['spearman'], axis=0, ascending=False) \n",
    "        df = df.reset_index(drop=True)\n",
    "        total_num = len(df)\n",
    "        trusted_num = math.floor(total_num * 0.3)\n",
    "        distrusted_num = math.floor(total_num * 0.3)\n",
    "        df[\"label\"] = -1\n",
    "        for i in range(trusted_num):\n",
    "            df.loc[i,\"label\"] = 1\n",
    "\n",
    "        for i in df.iloc[-distrusted_num:,:].index:\n",
    "            df.loc[i,\"label\"] = 0\n",
    "        df_list.append(df[df[\"label\"]!=-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110494e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>correlation</th>\n",
       "      <th>review</th>\n",
       "      <th>spearman</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.233982</td>\n",
       "      <td>0.766018</td>\n",
       "      <td>이거 안본 사람이랑 말 안함</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.994989</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>출연하신 모든 배우님들 정말 감사합니다. 김태리씨가 라디오를 녹음하시던 그 빨간 카...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.658633</td>\n",
       "      <td>0.141367</td>\n",
       "      <td>드라마틱하게 기억에 남습니다.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.965433</td>\n",
       "      <td>0.034567</td>\n",
       "      <td>아이에게 해줄말이 많았던영화</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.586564</td>\n",
       "      <td>0.413436</td>\n",
       "      <td>최고다. 그 시절을 기억하는 이들에게도  아닌 이들에게도.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  sentiment  correlation  \\\n",
       "0      10   0.233982     0.766018   \n",
       "1      10   0.994989     0.005011   \n",
       "2       8   0.658633     0.141367   \n",
       "3      10   0.965433     0.034567   \n",
       "4      10   0.586564     0.413436   \n",
       "\n",
       "                                              review  spearman  label  \n",
       "0                                   이거 안본 사람이랑 말 안함        1.0      1  \n",
       "1  출연하신 모든 배우님들 정말 감사합니다. 김태리씨가 라디오를 녹음하시던 그 빨간 카...       1.0      1  \n",
       "2                                  드라마틱하게 기억에 남습니다.        1.0      1  \n",
       "3                                   아이에게 해줄말이 많았던영화        1.0      1  \n",
       "4                  최고다. 그 시절을 기억하는 이들에게도  아닌 이들에게도.        1.0      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.concat(df_list, ignore_index=True)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db0503d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+01, 2.33981848e-01, 7.66018152e-01],\n",
       "       [1.00000000e+01, 9.94988620e-01, 5.01138000e-03],\n",
       "       [8.00000000e+00, 6.58632815e-01, 1.41367185e-01],\n",
       "       ...,\n",
       "       [8.00000000e+00, 9.96811390e-01, 1.96811390e-01],\n",
       "       [8.00000000e+00, 7.59411395e-01, 4.05886050e-02],\n",
       "       [1.00000000e+01, 9.81144547e-01, 1.88554530e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[[\"rating\",\"sentiment\",\"correlation\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c06b66d",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94445ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "numerical_features = result_df[[\"rating\",\"sentiment\",\"correlation\"]].values.reshape(-1,3,1)\n",
    "text_features = result_df[\"review\"]\n",
    "text_features = np.array([np.array(t) for t in text_features])\n",
    "y = result_df[\"label\"].values.astype('int32').reshape((-1,1))\n",
    "\n",
    "x_train, x_test,x_feature,x_test_feature, y_train, y_test = train_test_split(text_features,numerical_features, y, test_size=0.2, \n",
    "                                                 random_state=34, stratify=y,shuffle=True)\n",
    "x_train, x_val,x_feature,x_val_feature, y_train, y_val = train_test_split(x_train,x_feature, y_train, test_size=0.1, \n",
    "                                                 random_state=134,stratify=y_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56c1c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de0ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/distilkobert_cased_preprocess/1\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/jeongukjae/distilkobert_cased_L-3_H-768_A-12/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "595f3e82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.5429 - precision: 0.5379 - recall: 0.6073WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 549s 601ms/step - loss: 0.6870 - accuracy: 0.5429 - precision: 0.5379 - recall: 0.6073 - val_loss: 0.6845 - val_accuracy: 0.5432 - val_precision: 0.5551 - val_recall: 0.4361\n",
      "Epoch 2/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.5619 - precision: 0.5587 - recall: 0.5889WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 599ms/step - loss: 0.6808 - accuracy: 0.5619 - precision: 0.5587 - recall: 0.5889 - val_loss: 0.6822 - val_accuracy: 0.5591 - val_precision: 0.5592 - val_recall: 0.5595\n",
      "Epoch 3/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6779 - accuracy: 0.5679 - precision: 0.5658 - recall: 0.5834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6779 - accuracy: 0.5679 - precision: 0.5658 - recall: 0.5834 - val_loss: 0.6803 - val_accuracy: 0.5550 - val_precision: 0.5546 - val_recall: 0.5601\n",
      "Epoch 4/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6754 - accuracy: 0.5762 - precision: 0.5695 - recall: 0.6243WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6754 - accuracy: 0.5762 - precision: 0.5695 - recall: 0.6243 - val_loss: 0.6803 - val_accuracy: 0.5587 - val_precision: 0.5518 - val_recall: 0.6274\n",
      "Epoch 5/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6739 - accuracy: 0.5759 - precision: 0.5712 - recall: 0.6089WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6739 - accuracy: 0.5759 - precision: 0.5712 - recall: 0.6089 - val_loss: 0.6826 - val_accuracy: 0.5566 - val_precision: 0.5655 - val_recall: 0.4897\n",
      "Epoch 6/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.5835 - precision: 0.5767 - recall: 0.6280WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6698 - accuracy: 0.5835 - precision: 0.5767 - recall: 0.6280 - val_loss: 0.6807 - val_accuracy: 0.5700 - val_precision: 0.5756 - val_recall: 0.5340\n",
      "Epoch 7/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.5812 - precision: 0.5728 - recall: 0.6387WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6686 - accuracy: 0.5812 - precision: 0.5728 - recall: 0.6387 - val_loss: 0.6791 - val_accuracy: 0.5700 - val_precision: 0.5566 - val_recall: 0.6897\n",
      "Epoch 8/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.5887 - precision: 0.5789 - recall: 0.6511WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6654 - accuracy: 0.5887 - precision: 0.5789 - recall: 0.6511 - val_loss: 0.6825 - val_accuracy: 0.5765 - val_precision: 0.5661 - val_recall: 0.6567\n",
      "Epoch 9/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6629 - accuracy: 0.5921 - precision: 0.5824 - recall: 0.6509WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6629 - accuracy: 0.5921 - precision: 0.5824 - recall: 0.6509 - val_loss: 0.6810 - val_accuracy: 0.5756 - val_precision: 0.5851 - val_recall: 0.5202\n",
      "Epoch 10/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6598 - accuracy: 0.5961 - precision: 0.5859 - recall: 0.6556WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 541s 599ms/step - loss: 0.6598 - accuracy: 0.5961 - precision: 0.5859 - recall: 0.6556 - val_loss: 0.6827 - val_accuracy: 0.5687 - val_precision: 0.5623 - val_recall: 0.6218\n",
      "Epoch 11/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.5994 - precision: 0.5875 - recall: 0.6669WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6583 - accuracy: 0.5994 - precision: 0.5875 - recall: 0.6669 - val_loss: 0.6838 - val_accuracy: 0.5653 - val_precision: 0.5639 - val_recall: 0.5769\n",
      "Epoch 12/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.6013 - precision: 0.5901 - recall: 0.6637WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6549 - accuracy: 0.6013 - precision: 0.5901 - recall: 0.6637 - val_loss: 0.6811 - val_accuracy: 0.5690 - val_precision: 0.5646 - val_recall: 0.6044\n",
      "Epoch 13/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6511 - accuracy: 0.6054 - precision: 0.5927 - recall: 0.6735WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6511 - accuracy: 0.6054 - precision: 0.5927 - recall: 0.6735 - val_loss: 0.6868 - val_accuracy: 0.5662 - val_precision: 0.5810 - val_recall: 0.4760\n",
      "Epoch 14/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6490 - accuracy: 0.6071 - precision: 0.5952 - recall: 0.6691WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6490 - accuracy: 0.6071 - precision: 0.5952 - recall: 0.6691 - val_loss: 0.6868 - val_accuracy: 0.5644 - val_precision: 0.5555 - val_recall: 0.6455\n",
      "Epoch 15/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6439 - accuracy: 0.6115 - precision: 0.5980 - recall: 0.6803WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6439 - accuracy: 0.6115 - precision: 0.5980 - recall: 0.6803 - val_loss: 0.6899 - val_accuracy: 0.5644 - val_precision: 0.5665 - val_recall: 0.5495\n",
      "Epoch 16/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6408 - accuracy: 0.6158 - precision: 0.6032 - recall: 0.6768WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6408 - accuracy: 0.6158 - precision: 0.6032 - recall: 0.6768 - val_loss: 0.6937 - val_accuracy: 0.5653 - val_precision: 0.5637 - val_recall: 0.5788\n",
      "Epoch 17/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.6208 - precision: 0.6056 - recall: 0.6925WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6376 - accuracy: 0.6208 - precision: 0.6056 - recall: 0.6925 - val_loss: 0.7021 - val_accuracy: 0.5550 - val_precision: 0.5712 - val_recall: 0.4424\n",
      "Epoch 18/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.6239 - precision: 0.6100 - recall: 0.6874WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6333 - accuracy: 0.6239 - precision: 0.6100 - recall: 0.6874 - val_loss: 0.6908 - val_accuracy: 0.5587 - val_precision: 0.5474 - val_recall: 0.6798\n",
      "Epoch 19/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6279 - accuracy: 0.6297 - precision: 0.6139 - recall: 0.6987WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6279 - accuracy: 0.6297 - precision: 0.6139 - recall: 0.6987 - val_loss: 0.7082 - val_accuracy: 0.5587 - val_precision: 0.5579 - val_recall: 0.5670\n",
      "Epoch 20/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6266 - accuracy: 0.6262 - precision: 0.6092 - recall: 0.7038WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 539s 597ms/step - loss: 0.6266 - accuracy: 0.6262 - precision: 0.6092 - recall: 0.7038 - val_loss: 0.7145 - val_accuracy: 0.5578 - val_precision: 0.5557 - val_recall: 0.5782\n",
      "Epoch 21/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6221 - accuracy: 0.6321 - precision: 0.6147 - recall: 0.7080WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 539s 597ms/step - loss: 0.6221 - accuracy: 0.6321 - precision: 0.6147 - recall: 0.7080 - val_loss: 0.7175 - val_accuracy: 0.5566 - val_precision: 0.5467 - val_recall: 0.6642\n",
      "Epoch 22/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.6351 - precision: 0.6192 - recall: 0.7016WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 539s 597ms/step - loss: 0.6183 - accuracy: 0.6351 - precision: 0.6192 - recall: 0.7016 - val_loss: 0.7362 - val_accuracy: 0.5522 - val_precision: 0.5468 - val_recall: 0.6118\n",
      "Epoch 23/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6140 - accuracy: 0.6403 - precision: 0.6217 - recall: 0.7166WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 539s 597ms/step - loss: 0.6140 - accuracy: 0.6403 - precision: 0.6217 - recall: 0.7166 - val_loss: 0.7260 - val_accuracy: 0.5566 - val_precision: 0.5479 - val_recall: 0.6486\n",
      "Epoch 24/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.6400 - precision: 0.6217 - recall: 0.7150WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 539s 597ms/step - loss: 0.6123 - accuracy: 0.6400 - precision: 0.6217 - recall: 0.7150 - val_loss: 0.7251 - val_accuracy: 0.5481 - val_precision: 0.5492 - val_recall: 0.5389\n",
      "Epoch 25/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.6420 - precision: 0.6225 - recall: 0.7213WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6084 - accuracy: 0.6420 - precision: 0.6225 - recall: 0.7213 - val_loss: 0.7390 - val_accuracy: 0.5628 - val_precision: 0.5542 - val_recall: 0.6436\n",
      "Epoch 26/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6046 - accuracy: 0.6465 - precision: 0.6289 - recall: 0.7145WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6046 - accuracy: 0.6465 - precision: 0.6289 - recall: 0.7145 - val_loss: 0.7415 - val_accuracy: 0.5494 - val_precision: 0.5402 - val_recall: 0.6660\n",
      "Epoch 27/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.6026 - accuracy: 0.6484 - precision: 0.6298 - recall: 0.7203WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.6026 - accuracy: 0.6484 - precision: 0.6298 - recall: 0.7203 - val_loss: 0.7517 - val_accuracy: 0.5597 - val_precision: 0.5464 - val_recall: 0.7047\n",
      "Epoch 28/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.5965 - accuracy: 0.6525 - precision: 0.6319 - recall: 0.7308WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 539s 597ms/step - loss: 0.5965 - accuracy: 0.6525 - precision: 0.6319 - recall: 0.7308 - val_loss: 0.7517 - val_accuracy: 0.5541 - val_precision: 0.5460 - val_recall: 0.6436\n",
      "Epoch 29/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.6567 - precision: 0.6355 - recall: 0.7351WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/903 [==============================] - 540s 598ms/step - loss: 0.5935 - accuracy: 0.6567 - precision: 0.6355 - recall: 0.7351 - val_loss: 0.7667 - val_accuracy: 0.5491 - val_precision: 0.5382 - val_recall: 0.6941\n",
      "Epoch 30/30\n",
      "903/903 [==============================] - ETA: 0s - loss: 0.5917 - accuracy: 0.6579 - precision: 0.6370 - recall: 0.7340WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "903/903 [==============================] - 539s 597ms/step - loss: 0.5917 - accuracy: 0.6579 - precision: 0.6370 - recall: 0.7340 - val_loss: 0.7808 - val_accuracy: 0.5538 - val_precision: 0.5468 - val_recall: 0.6299\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mfit([x_train,x_feature], y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[mc],validation_data\u001b[38;5;241m=\u001b[39m([x_val,x_val_feature], y_val))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# multi input 이면 꼭!!! validation도 []로 묶어주는 거 잊지 말기..\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m result1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate([y_test,\u001b[43my_test_feature\u001b[49m], y_test) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_feature' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='review')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "\n",
    "feature_input = tf.keras.layers.Input(shape=(3,1),)\n",
    "feature_output = tf.keras.layers.Dense(3,activation=\"relu\")(feature_input)\n",
    "feature_output = tf.keras.layers.Flatten()(feature_output)\n",
    "\n",
    "\n",
    "concatenated = tf.keras.layers.concatenate([l, feature_output])\n",
    "concat_reshape = tf.keras.layers.Reshape((1,777))(concatenated) # reshape 2d to 3d\n",
    "concat_out = tf.keras.layers.LSTM(32, return_sequences=True)(concat_reshape)\n",
    "concat_out = tf.keras.layers.LSTM(32, return_sequences=True)(concat_out)\n",
    "concat_out = tf.keras.layers.LSTM(32)(concat_out)\n",
    "concat_out = tf.keras.layers.Dense(1, activation='sigmoid')(concat_out)\n",
    "#concat_out = tf.keras.layers.LSTM(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "model = tf.keras.models.Model([text_input, feature_input], concat_out)\n",
    "\n",
    "\n",
    "\n",
    "mc = ModelCheckpoint('best_review_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    " loss='binary_crossentropy',\n",
    " metrics=['acc'])\n",
    "model.fit([x_train,x_feature], y_train, epochs=30,batch_size=32, callbacks=[mc],validation_data=([x_val,x_val_feature], y_val))\n",
    "# multi input 이면 꼭!!! validation도 []로 묶어주는 거 잊지 말기..\n",
    "result1 = model.evaluate([x_test,x_test_feature], y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c8087414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_result(n):\n",
    "    if n > 0.4: \n",
    "        result=1\n",
    "    else: result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75dac0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 134s 535ms/step - loss: 0.7892 - accuracy: 0.5578 - precision: 0.5507 - recall: 0.6285\n"
     ]
    }
   ],
   "source": [
    "result1 = model.evaluate([x_test,x_test_feature], y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fec910c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 134s 535ms/step\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict([x_test,x_test_feature]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "882f433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.6325695581014731 \n",
      " accuracy : 0.5522313637496884\n"
     ]
    }
   ],
   "source": [
    "y_pred = list(map(prediction_result, test_prediction))\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#  threshikd = 0.4\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"f1 score : {f1} \\n accuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f0f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09688bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a94b6559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: review_classification/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: review_classification/assets\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"review_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fe1e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlaws = pd.read_csv(\"./preprocessed_data/the outlaws.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6eee3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlaws = outlaws[[\"rating\", \"sentiment\", \"correlation\",\"review\",\"spearman\"]]\n",
    "outlaws[\"spearman\"] = outlaws[\"spearman\"].abs() # 절대값으로 변환, 상관계수가 음의 방향으로 커도 상관관계의 정도가 큰 것이기 때문\n",
    "outlaws = outlaws.sort_values(by=['spearman'], axis=0, ascending=False) \n",
    "outlaws = outlaws.reset_index(drop=True)\n",
    "total_num = len(outlaws)\n",
    "trusted_num = math.floor(total_num * 0.5)\n",
    "distrusted_num = total_num - trusted_num\n",
    "for i in range(trusted_num):\n",
    "    outlaws.loc[i,\"label\"] = 1\n",
    "\n",
    "for i in outlaws.iloc[-distrusted_num:,:].index:\n",
    "    outlaws.loc[i,\"label\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a6f07bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerical_features = outlaws[[\"rating\",\"sentiment\",\"correlation\"]].values.reshape(-1,3,1)\n",
    "text_features = outlaws[\"review\"]\n",
    "text_features = np.array([np.array(t).astype('<U140') for t in text_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53e5151f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/508 [==============================] - 272s 535ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([text_features,numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e03cf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>correlation</th>\n",
       "      <th>review</th>\n",
       "      <th>spearman</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.428564</td>\n",
       "      <td>0.371436</td>\n",
       "      <td>생각보다 스토리범위가 너무좁았다 영화내내 칼빵만</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.917745</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>윤계상 연기 잘하네요!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.742317</td>\n",
       "      <td>0.157683</td>\n",
       "      <td>아무생각없이 즐겁게 보기 괜찮은 영화인듯 ㅋㅋ줄거린 별거 없다 ㅋㅋ 마동성 아저씨 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.750091</td>\n",
       "      <td>0.249909</td>\n",
       "      <td>꾸루루루루잼!!!ㅎㅎㅎ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>지루해 윤계상 연기변신은 괜찬</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16235</th>\n",
       "      <td>10</td>\n",
       "      <td>0.574636</td>\n",
       "      <td>0.425364</td>\n",
       "      <td>꼭보세요. 진짜재미남요 1초도 안지루함</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16236</th>\n",
       "      <td>5</td>\n",
       "      <td>0.679526</td>\n",
       "      <td>0.179526</td>\n",
       "      <td>마동석 캐릭터는 말안해도 매력적이며 윤계상은 재발견수준!하지만 피칠갑을 덧씌우며 벌...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16237</th>\n",
       "      <td>9</td>\n",
       "      <td>0.941423</td>\n",
       "      <td>0.041423</td>\n",
       "      <td>생각보다 덜 잔인해서 더 재밌게본듯</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16238</th>\n",
       "      <td>10</td>\n",
       "      <td>0.889599</td>\n",
       "      <td>0.110401</td>\n",
       "      <td>중간중간 재미있는 요소들이 튀어나와서 더 즐겁게 봤네요!ㅋㅋㅋ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16239</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.899294</td>\n",
       "      <td>연기도좋고 내용도 재밌는데 룸싸롱 성매매 이런걸 꼭 넣어야 됐을까 생각이드네요 너무...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating  sentiment  correlation  \\\n",
       "0           8   0.428564     0.371436   \n",
       "1           9   0.917745     0.017745   \n",
       "2           9   0.742317     0.157683   \n",
       "3          10   0.750091     0.249909   \n",
       "4           1   0.096552     0.003448   \n",
       "...       ...        ...          ...   \n",
       "16235      10   0.574636     0.425364   \n",
       "16236       5   0.679526     0.179526   \n",
       "16237       9   0.941423     0.041423   \n",
       "16238      10   0.889599     0.110401   \n",
       "16239       1   0.999294     0.899294   \n",
       "\n",
       "                                                  review  spearman  label  \n",
       "0                            생각보다 스토리범위가 너무좁았다 영화내내 칼빵만        1.0    1.0  \n",
       "1                                          윤계상 연기 잘하네요!        1.0    1.0  \n",
       "2      아무생각없이 즐겁게 보기 괜찮은 영화인듯 ㅋㅋ줄거린 별거 없다 ㅋㅋ 마동성 아저씨 ...       1.0    1.0  \n",
       "3                                          꾸루루루루잼!!!ㅎㅎㅎ        1.0    1.0  \n",
       "4                                      지루해 윤계상 연기변신은 괜찬        1.0    1.0  \n",
       "...                                                  ...       ...    ...  \n",
       "16235                             꼭보세요. 진짜재미남요 1초도 안지루함        0.0    0.0  \n",
       "16236  마동석 캐릭터는 말안해도 매력적이며 윤계상은 재발견수준!하지만 피칠갑을 덧씌우며 벌...       0.0    0.0  \n",
       "16237                               생각보다 덜 잔인해서 더 재밌게본듯        0.0    0.0  \n",
       "16238                중간중간 재미있는 요소들이 튀어나와서 더 즐겁게 봤네요!ㅋㅋㅋ        0.0    0.0  \n",
       "16239  연기도좋고 내용도 재밌는데 룸싸롱 성매매 이런걸 꼭 넣어야 됐을까 생각이드네요 너무...       0.0    0.0  \n",
       "\n",
       "[16240 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlaws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "522a4031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6855989 ],\n",
       "       [0.62675214],\n",
       "       [0.5195645 ],\n",
       "       ...,\n",
       "       [0.5169674 ],\n",
       "       [0.59649056],\n",
       "       [0.470961  ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "656c7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_result(n):\n",
    "    if n > 0.4: \n",
    "        result=1\n",
    "    else: result = 0\n",
    "    return result\n",
    "\n",
    "result2 = list(map(prediction_result, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ecdbfa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# 데이터 스플릿으로 y_valid와 모델 예측으로 y_pred를 구한 후 실행\n",
    "# 모델 검정이 없다면 y_true값으로 y_valid 대체\n",
    "f1 = f1_score(outlaws[\"label\"].values, result2)\n",
    "accuracy = accuracy_score(outlaws[\"label\"].values, result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb71d3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5648028251912889\n",
      "0.5447044334975369\n"
     ]
    }
   ],
   "source": [
    "# threshold 0.5\n",
    "print(f1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83f0cbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36002347614655816\n",
      "0.529987684729064\n"
     ]
    }
   ],
   "source": [
    "# threshold 0.6\n",
    "print(f1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "863549c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617892030848329\n",
      "0.5423645320197045\n"
     ]
    }
   ],
   "source": [
    "# threshold 0.4\n",
    "print(f1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fd89ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlaws[\"prediction_score\"] = predictions\n",
    "outlaws[\"predicted_label\"] = result2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "81ff6d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>correlation</th>\n",
       "      <th>review</th>\n",
       "      <th>spearman</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.428564</td>\n",
       "      <td>0.371436</td>\n",
       "      <td>생각보다 스토리범위가 너무좁았다 영화내내 칼빵만</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.685599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.917745</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>윤계상 연기 잘하네요!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.626752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.742317</td>\n",
       "      <td>0.157683</td>\n",
       "      <td>아무생각없이 즐겁게 보기 괜찮은 영화인듯 ㅋㅋ줄거린 별거 없다 ㅋㅋ 마동성 아저씨 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.519565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.750091</td>\n",
       "      <td>0.249909</td>\n",
       "      <td>꾸루루루루잼!!!ㅎㅎㅎ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.201239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>지루해 윤계상 연기변신은 괜찬</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.870583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16235</th>\n",
       "      <td>10</td>\n",
       "      <td>0.574636</td>\n",
       "      <td>0.425364</td>\n",
       "      <td>꼭보세요. 진짜재미남요 1초도 안지루함</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16236</th>\n",
       "      <td>5</td>\n",
       "      <td>0.679526</td>\n",
       "      <td>0.179526</td>\n",
       "      <td>마동석 캐릭터는 말안해도 매력적이며 윤계상은 재발견수준!하지만 피칠갑을 덧씌우며 벌...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407270</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16237</th>\n",
       "      <td>9</td>\n",
       "      <td>0.941423</td>\n",
       "      <td>0.041423</td>\n",
       "      <td>생각보다 덜 잔인해서 더 재밌게본듯</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16238</th>\n",
       "      <td>10</td>\n",
       "      <td>0.889599</td>\n",
       "      <td>0.110401</td>\n",
       "      <td>중간중간 재미있는 요소들이 튀어나와서 더 즐겁게 봤네요!ㅋㅋㅋ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16239</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.899294</td>\n",
       "      <td>연기도좋고 내용도 재밌는데 룸싸롱 성매매 이런걸 꼭 넣어야 됐을까 생각이드네요 너무...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.470961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating  sentiment  correlation  \\\n",
       "0           8   0.428564     0.371436   \n",
       "1           9   0.917745     0.017745   \n",
       "2           9   0.742317     0.157683   \n",
       "3          10   0.750091     0.249909   \n",
       "4           1   0.096552     0.003448   \n",
       "...       ...        ...          ...   \n",
       "16235      10   0.574636     0.425364   \n",
       "16236       5   0.679526     0.179526   \n",
       "16237       9   0.941423     0.041423   \n",
       "16238      10   0.889599     0.110401   \n",
       "16239       1   0.999294     0.899294   \n",
       "\n",
       "                                                  review  spearman  label  \\\n",
       "0                            생각보다 스토리범위가 너무좁았다 영화내내 칼빵만        1.0    1.0   \n",
       "1                                          윤계상 연기 잘하네요!        1.0    1.0   \n",
       "2      아무생각없이 즐겁게 보기 괜찮은 영화인듯 ㅋㅋ줄거린 별거 없다 ㅋㅋ 마동성 아저씨 ...       1.0    1.0   \n",
       "3                                          꾸루루루루잼!!!ㅎㅎㅎ        1.0    1.0   \n",
       "4                                      지루해 윤계상 연기변신은 괜찬        1.0    1.0   \n",
       "...                                                  ...       ...    ...   \n",
       "16235                             꼭보세요. 진짜재미남요 1초도 안지루함        0.0    0.0   \n",
       "16236  마동석 캐릭터는 말안해도 매력적이며 윤계상은 재발견수준!하지만 피칠갑을 덧씌우며 벌...       0.0    0.0   \n",
       "16237                               생각보다 덜 잔인해서 더 재밌게본듯        0.0    0.0   \n",
       "16238                중간중간 재미있는 요소들이 튀어나와서 더 즐겁게 봤네요!ㅋㅋㅋ        0.0    0.0   \n",
       "16239  연기도좋고 내용도 재밌는데 룸싸롱 성매매 이런걸 꼭 넣어야 됐을까 생각이드네요 너무...       0.0    0.0   \n",
       "\n",
       "       prediction_score  predicted_label  \n",
       "0              0.685599                1  \n",
       "1              0.626752                1  \n",
       "2              0.519565                1  \n",
       "3              0.201239                0  \n",
       "4              0.870583                1  \n",
       "...                 ...              ...  \n",
       "16235          0.556065                1  \n",
       "16236          0.407270                1  \n",
       "16237          0.516967                1  \n",
       "16238          0.596491                1  \n",
       "16239          0.470961                1  \n",
       "\n",
       "[16240 rows x 8 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlaws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0059eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outlaws = outlaws.sort_values(by=['prediction_score'], axis=0, ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4af6997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>correlation</th>\n",
       "      <th>review</th>\n",
       "      <th>spearman</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.253529</td>\n",
       "      <td>0.053529</td>\n",
       "      <td>징그러운거 잔인한거 아이보니 그럼 비추</td>\n",
       "      <td>0.202797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.233134</td>\n",
       "      <td>0.133134</td>\n",
       "      <td>개무서움 덜덜 진짜 개무서움 덜덜더르</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.022273</td>\n",
       "      <td>0.077727</td>\n",
       "      <td>극혐도시 폭동도시 쓰레기</td>\n",
       "      <td>0.343166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.087828</td>\n",
       "      <td>쓰레기임 폭력성만 강조한 냉무영화</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.524306</td>\n",
       "      <td>0.475694</td>\n",
       "      <td>범죄도시&gt;&gt;&gt;범죄와의 전쟁</td>\n",
       "      <td>0.398527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16235</th>\n",
       "      <td>10</td>\n",
       "      <td>0.524306</td>\n",
       "      <td>0.475694</td>\n",
       "      <td>동석이형 존멋 개꿀잼이여</td>\n",
       "      <td>0.175718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16236</th>\n",
       "      <td>8</td>\n",
       "      <td>0.262457</td>\n",
       "      <td>0.537543</td>\n",
       "      <td>마동석에의한,위한,의 도시</td>\n",
       "      <td>0.604933</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16237</th>\n",
       "      <td>1</td>\n",
       "      <td>0.323128</td>\n",
       "      <td>0.223128</td>\n",
       "      <td>조폭에서 벗어나질 못 하는</td>\n",
       "      <td>0.690174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16238</th>\n",
       "      <td>8</td>\n",
       "      <td>0.605670</td>\n",
       "      <td>0.194330</td>\n",
       "      <td>범죄의도시범죄의도시</td>\n",
       "      <td>0.752139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16239</th>\n",
       "      <td>10</td>\n",
       "      <td>0.524306</td>\n",
       "      <td>0.475694</td>\n",
       "      <td>레알 개꿀쟘 계상이형 오졋음</td>\n",
       "      <td>0.339563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16240 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating  sentiment  correlation                  review  spearman  \\\n",
       "0           2   0.253529     0.053529  징그러운거 잔인한거 아이보니 그럼 비추   0.202797   \n",
       "1           1   0.233134     0.133134   개무서움 덜덜 진짜 개무서움 덜덜더르   1.000000   \n",
       "2           1   0.022273     0.077727          극혐도시 폭동도시 쓰레기   0.343166   \n",
       "3           1   0.012172     0.087828     쓰레기임 폭력성만 강조한 냉무영화   0.866025   \n",
       "4          10   0.524306     0.475694         범죄도시>>>범죄와의 전쟁   0.398527   \n",
       "...       ...        ...          ...                     ...       ...   \n",
       "16235      10   0.524306     0.475694          동석이형 존멋 개꿀잼이여   0.175718   \n",
       "16236       8   0.262457     0.537543         마동석에의한,위한,의 도시   0.604933   \n",
       "16237       1   0.323128     0.223128         조폭에서 벗어나질 못 하는   0.690174   \n",
       "16238       8   0.605670     0.194330             범죄의도시범죄의도시   0.752139   \n",
       "16239      10   0.524306     0.475694        레알 개꿀쟘 계상이형 오졋음   0.339563   \n",
       "\n",
       "       label  prediction_score  predicted_label  \n",
       "0        0.0          0.998938                1  \n",
       "1        1.0          0.998797                1  \n",
       "2        0.0          0.998783                1  \n",
       "3        1.0          0.998727                1  \n",
       "4        0.0          0.998500                1  \n",
       "...      ...               ...              ...  \n",
       "16235    0.0          0.000606                0  \n",
       "16236    1.0          0.000599                0  \n",
       "16237    1.0          0.000594                0  \n",
       "16238    1.0          0.000588                0  \n",
       "16239    0.0          0.000546                0  \n",
       "\n",
       "[16240 rows x 8 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_outlaws = new_outlaws.reset_index(drop=True)\n",
    "new_outlaws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "06197866",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outlaws.to_csv(\"./result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d3015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lim",
   "language": "python",
   "name": "lim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
